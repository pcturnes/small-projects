{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07cbb8f9",
   "metadata": {},
   "source": [
    "## ðŸ“˜ Notebook Overview\n",
    "\n",
    "This notebook presents a complete predictive modeling analysis aimed at explaining and predicting a product **rating** variable using supervised learning techniques.\n",
    "\n",
    "This is the second part of the assignment, where we integrate a GLM to to some prediction modelling. The first part can be seen in the notebook lin_reg_1.ipynb. This first part serves as a baseline and provides an initial understanding of the relationship between the explanatory variables and the response.\n",
    "\n",
    "In the second part, a **Generalized Linear Model (GLM)** is estimated to extend the linear regression framework. Given that the response variable is strictly positive and exhibits right-skewness, a **Gamma distribution with a log link function** is employed. The same dataset, preprocessing pipeline, and train/test split are retained to ensure a fair and consistent comparison between models.\n",
    "\n",
    "For both approaches, model interpretation, predictive performance, and uncertainty quantification through prediction intervals are discussed. The notebook concludes with a comparison of the two modeling strategies and a summary of the main findings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9efa89",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12454d90",
   "metadata": {},
   "source": [
    "\n",
    "This section includes all the Python libraries required for data manipulation, visualization, modeling, and evaluation throughout the notebook.\n",
    "\n",
    "The main libraries used are:\n",
    "- **NumPy** and **Pandas** for numerical computations and data handling.\n",
    "- **Matplotlib / Seaborn** for exploratory data analysis and visualization.\n",
    "- **scikit-learn** for preprocessing, train/test splitting, baseline models, and performance metrics.\n",
    "- **statsmodels** for statistical modeling, in particular for the implementation of the Generalized Linear Model (GLM).\n",
    "\n",
    "All imports are grouped at the beginning of the notebook to improve readability and reproducibility.\n",
    "\n",
    "The data is imported from the same folder where this notebook is placed. The data is divided into train and test sets (only those datpoints that have the target variable, as some of them are missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da58a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# statsmodels imports\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# sklearn imports\n",
    "# split\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "# impute\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# pipeline and column transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# feature extraction\n",
    "from sklearn.preprocessing import TargetEncoder, StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from category_encoders import TargetEncoder as SafeTargetEncoder\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb3b7266",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BigBasket Products.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb230072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA SEPARATION\n",
      "============================================================\n",
      "Dataset with rating (df): 18929 rows\n",
      "Dataset without rating (test_no_target): 8626 rows\n",
      "Total: 27555 rows\n"
     ]
    }
   ],
   "source": [
    "# Separate data with missing ratings for later prediction\n",
    "test_no_target = df[df['rating'].isnull()].copy()\n",
    "df = df[df['rating'].notnull()].copy()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATA SEPARATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Dataset with rating (df): {df.shape[0]} rows\")\n",
    "print(f\"Dataset without rating (test_no_target): {test_no_target.shape[0]} rows\")\n",
    "print(f\"Total: {df.shape[0] + test_no_target.shape[0]} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7e03b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAIN-TEST SPLIT\n",
      "============================================================\n",
      "Training set: 13250 rows (70.0%)\n",
      "Test set: 5679 rows (30.0%)\n",
      "Total: 18929 rows\n"
     ]
    }
   ],
   "source": [
    "# Split data into training (70%) and testing (30%)\n",
    "df_train, df_test = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAIN-TEST SPLIT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training set: {df_train.shape[0]} rows ({100*df_train.shape[0]/(df_train.shape[0]+df_test.shape[0]):.1f}%)\")\n",
    "print(f\"Test set: {df_test.shape[0]} rows ({100*df_test.shape[0]/(df_train.shape[0]+df_test.shape[0]):.1f}%)\")\n",
    "print(f\"Total: {df_train.shape[0] + df_test.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c2f9f7",
   "metadata": {},
   "source": [
    "## ðŸ§¹ Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48fb2bc",
   "metadata": {},
   "source": [
    "\n",
    "Prior to model estimation, the dataset was preprocessed to ensure compatibility with the considered models and to improve predictive performance.\n",
    "\n",
    "The main preprocessing steps include:\n",
    "- Defining the target variable (**rating**) and the set of input variables.\n",
    "- Handling categorical variables through appropriate encoding techniques.\n",
    "- Applying feature scaling where necessary.\n",
    "- Splitting the data into **training** and **test** sets to allow for an out-of-sample evaluation of model performance.\n",
    "\n",
    "This same preprocessing pipeline is also used for the first model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1954220d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop('rating', axis=1)\n",
    "y_train = df_train['rating']\n",
    "X_test = df_test.drop('rating', axis=1)\n",
    "y_test = df_test['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1e193a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define steps for numerical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('log_transform', FunctionTransformer(np.log1p, validate=True)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Define steps for categorical features (Target Encoding)\n",
    "categorical_transformer = TargetEncoder(smooth='auto') \n",
    "\n",
    "# Define steps for one-hot features\n",
    "ohe_transformer = OneHotEncoder(handle_unknown='ignore', drop='first')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, ['sale_price', 'market_price']),\n",
    "        ('target_cat', categorical_transformer, ['brand', 'sub_category']),\n",
    "        ('ohe_cat', ohe_transformer, ['category']) \n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Now, apply to your data:\n",
    "X_train_preprocessed = pd.DataFrame(preprocessor.fit_transform(X_train, y_train))\n",
    "X_test_preprocessed = pd.DataFrame(preprocessor.transform(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b78efb",
   "metadata": {},
   "source": [
    "## ðŸ§  Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbef91f",
   "metadata": {},
   "source": [
    "\n",
    "In this section, a **Generalized Linear Model (GLM)** is estimated to model the rating variable and to extend the linear regression framework presented previously.\n",
    "\n",
    "The same preprocessed feature matrices used in the linear regression analysis are retained. Since `statsmodels` does not automatically include an intercept term, a constant column is explicitly added to both the training and test feature matrices. Indexes are also reset to ensure proper alignment between the response variable and the design matrix.\n",
    "\n",
    "The model is specified using a **Gamma distribution** with a **log link function**, which is appropriate for strictly positive and right-skewed response variables. Model parameters are estimated using the **Iteratively Reweighted Least Squares (IRLS)** algorithm.\n",
    "\n",
    "After fitting the model on the training data, parameter estimates and inference statistics are examined. Finally, predictions are generated on the test set to allow for an out-of-sample evaluation of predictive performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c97296a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_glm = sm.add_constant(X_train_preprocessed)\n",
    "X_train_glm = X_train_glm.reset_index(drop=True)\n",
    "y_train_glm = y_train.reset_index(drop=True)\n",
    "\n",
    "X_test_glm = sm.add_constant(X_test_preprocessed)\n",
    "X_test_glm = X_test_glm.reset_index(drop=True)\n",
    "y_test_glm = y_test.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9a6a024b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pcturnes/Documents/Projects/.conda/lib/python3.11/site-packages/statsmodels/genmod/families/links.py:13: FutureWarning: The log link alias is deprecated. Use Log instead. The log link alias will be removed after the 0.15.0 release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "glm_gamma = sm.GLM(\n",
    "    y_train_glm,\n",
    "    X_train_glm,\n",
    "    family=sm.families.Gamma(sm.families.links.log())\n",
    ")\n",
    "\n",
    "glm_gamma_results = glm_gamma.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "606e057b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>rating</td>      <th>  No. Observations:  </th>  <td> 13250</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 13237</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>          <td>Gamma</td>      <th>  Df Model:          </th>  <td>    12</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>log</td>       <th>  Scale:             </th> <td>0.034123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -17233.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sat, 13 Dec 2025</td> <th>  Deviance:          </th> <td>  653.01</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>14:39:58</td>     <th>  Pearson chi2:      </th>  <td>  452.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>9</td>        <th>  Pseudo R-squ. (CS):</th>  <td>0.1002</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.4009</td> <td>    0.049</td> <td>    8.247</td> <td> 0.000</td> <td>    0.306</td> <td>    0.496</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0</th>     <td>    0.0003</td> <td>    0.009</td> <td>    0.035</td> <td> 0.972</td> <td>   -0.017</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1</th>     <td>   -0.0123</td> <td>    0.009</td> <td>   -1.337</td> <td> 0.181</td> <td>   -0.030</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2</th>     <td>    0.1335</td> <td>    0.005</td> <td>   27.634</td> <td> 0.000</td> <td>    0.124</td> <td>    0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3</th>     <td>    0.1138</td> <td>    0.012</td> <td>    9.313</td> <td> 0.000</td> <td>    0.090</td> <td>    0.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4</th>     <td>   -0.0173</td> <td>    0.013</td> <td>   -1.289</td> <td> 0.197</td> <td>   -0.044</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5</th>     <td>   -0.0077</td> <td>    0.011</td> <td>   -0.731</td> <td> 0.465</td> <td>   -0.028</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6</th>     <td>   -0.0016</td> <td>    0.014</td> <td>   -0.119</td> <td> 0.905</td> <td>   -0.028</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7</th>     <td>   -0.0075</td> <td>    0.011</td> <td>   -0.670</td> <td> 0.503</td> <td>   -0.030</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8</th>     <td>   -0.0073</td> <td>    0.011</td> <td>   -0.645</td> <td> 0.519</td> <td>   -0.029</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9</th>     <td>   -0.0058</td> <td>    0.011</td> <td>   -0.530</td> <td> 0.596</td> <td>   -0.027</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10</th>    <td>   -0.0047</td> <td>    0.011</td> <td>   -0.408</td> <td> 0.683</td> <td>   -0.027</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11</th>    <td>   -0.0164</td> <td>    0.011</td> <td>   -1.463</td> <td> 0.144</td> <td>   -0.038</td> <td>    0.006</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}   &      rating      & \\textbf{  No. Observations:  } &    13250    \\\\\n",
       "\\textbf{Model:}           &       GLM        & \\textbf{  Df Residuals:      } &    13237    \\\\\n",
       "\\textbf{Model Family:}    &      Gamma       & \\textbf{  Df Model:          } &       12    \\\\\n",
       "\\textbf{Link Function:}   &       log        & \\textbf{  Scale:             } &  0.034123   \\\\\n",
       "\\textbf{Method:}          &       IRLS       & \\textbf{  Log-Likelihood:    } &   -17233.   \\\\\n",
       "\\textbf{Date:}            & Sat, 13 Dec 2025 & \\textbf{  Deviance:          } &    653.01   \\\\\n",
       "\\textbf{Time:}            &     14:39:58     & \\textbf{  Pearson chi2:      } &     452.    \\\\\n",
       "\\textbf{No. Iterations:}  &        9         & \\textbf{  Pseudo R-squ. (CS):} &   0.1002    \\\\\n",
       "\\textbf{Covariance Type:} &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       0.4009  &        0.049     &     8.247  &         0.000        &        0.306    &        0.496     \\\\\n",
       "\\textbf{0}     &       0.0003  &        0.009     &     0.035  &         0.972        &       -0.017    &        0.018     \\\\\n",
       "\\textbf{1}     &      -0.0123  &        0.009     &    -1.337  &         0.181        &       -0.030    &        0.006     \\\\\n",
       "\\textbf{2}     &       0.1335  &        0.005     &    27.634  &         0.000        &        0.124    &        0.143     \\\\\n",
       "\\textbf{3}     &       0.1138  &        0.012     &     9.313  &         0.000        &        0.090    &        0.138     \\\\\n",
       "\\textbf{4}     &      -0.0173  &        0.013     &    -1.289  &         0.197        &       -0.044    &        0.009     \\\\\n",
       "\\textbf{5}     &      -0.0077  &        0.011     &    -0.731  &         0.465        &       -0.028    &        0.013     \\\\\n",
       "\\textbf{6}     &      -0.0016  &        0.014     &    -0.119  &         0.905        &       -0.028    &        0.025     \\\\\n",
       "\\textbf{7}     &      -0.0075  &        0.011     &    -0.670  &         0.503        &       -0.030    &        0.014     \\\\\n",
       "\\textbf{8}     &      -0.0073  &        0.011     &    -0.645  &         0.519        &       -0.029    &        0.015     \\\\\n",
       "\\textbf{9}     &      -0.0058  &        0.011     &    -0.530  &         0.596        &       -0.027    &        0.016     \\\\\n",
       "\\textbf{10}    &      -0.0047  &        0.011     &    -0.408  &         0.683        &       -0.027    &        0.018     \\\\\n",
       "\\textbf{11}    &      -0.0164  &        0.011     &    -1.463  &         0.144        &       -0.038    &        0.006     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Generalized Linear Model Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                 rating   No. Observations:                13250\n",
       "Model:                            GLM   Df Residuals:                    13237\n",
       "Model Family:                   Gamma   Df Model:                           12\n",
       "Link Function:                    log   Scale:                        0.034123\n",
       "Method:                          IRLS   Log-Likelihood:                -17233.\n",
       "Date:                Sat, 13 Dec 2025   Deviance:                       653.01\n",
       "Time:                        14:39:58   Pearson chi2:                     452.\n",
       "No. Iterations:                     9   Pseudo R-squ. (CS):             0.1002\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.4009      0.049      8.247      0.000       0.306       0.496\n",
       "0              0.0003      0.009      0.035      0.972      -0.017       0.018\n",
       "1             -0.0123      0.009     -1.337      0.181      -0.030       0.006\n",
       "2              0.1335      0.005     27.634      0.000       0.124       0.143\n",
       "3              0.1138      0.012      9.313      0.000       0.090       0.138\n",
       "4             -0.0173      0.013     -1.289      0.197      -0.044       0.009\n",
       "5             -0.0077      0.011     -0.731      0.465      -0.028       0.013\n",
       "6             -0.0016      0.014     -0.119      0.905      -0.028       0.025\n",
       "7             -0.0075      0.011     -0.670      0.503      -0.030       0.014\n",
       "8             -0.0073      0.011     -0.645      0.519      -0.029       0.015\n",
       "9             -0.0058      0.011     -0.530      0.596      -0.027       0.016\n",
       "10            -0.0047      0.011     -0.408      0.683      -0.027       0.018\n",
       "11            -0.0164      0.011     -1.463      0.144      -0.038       0.006\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_gamma_results.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf78246",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_glm = glm_gamma_results.predict(X_test_glm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b1af4f",
   "metadata": {},
   "source": [
    "## ðŸ“Š Analysis and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6569dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.46285998015838353, 0.5047628274858941)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_glm = mean_absolute_error(y_test_glm, y_pred_test_glm)\n",
    "mse_glm = mean_squared_error(y_test_glm, y_pred_test_glm)\n",
    "\n",
    "mae_glm, mse_glm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0b45af65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_glm = glm_gamma_results.get_prediction(X_test_glm)\n",
    "pred_summary = pred_glm.summary_frame(alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4b41ed00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean_se</th>\n",
       "      <th>mean_ci_lower</th>\n",
       "      <th>mean_ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.700570</td>\n",
       "      <td>0.016779</td>\n",
       "      <td>3.667828</td>\n",
       "      <td>3.733603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.313474</td>\n",
       "      <td>0.026658</td>\n",
       "      <td>4.261541</td>\n",
       "      <td>4.366040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.006404</td>\n",
       "      <td>0.018691</td>\n",
       "      <td>3.969938</td>\n",
       "      <td>4.043205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.963245</td>\n",
       "      <td>0.026625</td>\n",
       "      <td>3.911403</td>\n",
       "      <td>4.015774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.555119</td>\n",
       "      <td>0.021661</td>\n",
       "      <td>3.512917</td>\n",
       "      <td>3.597829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5674</th>\n",
       "      <td>4.031204</td>\n",
       "      <td>0.014193</td>\n",
       "      <td>4.003482</td>\n",
       "      <td>4.059118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5675</th>\n",
       "      <td>4.261949</td>\n",
       "      <td>0.038474</td>\n",
       "      <td>4.187205</td>\n",
       "      <td>4.338029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5676</th>\n",
       "      <td>3.922421</td>\n",
       "      <td>0.021054</td>\n",
       "      <td>3.881373</td>\n",
       "      <td>3.963904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5677</th>\n",
       "      <td>3.845409</td>\n",
       "      <td>0.017438</td>\n",
       "      <td>3.811384</td>\n",
       "      <td>3.879738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>4.002508</td>\n",
       "      <td>0.015089</td>\n",
       "      <td>3.973042</td>\n",
       "      <td>4.032191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5679 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean   mean_se  mean_ci_lower  mean_ci_upper\n",
       "0     3.700570  0.016779       3.667828       3.733603\n",
       "1     4.313474  0.026658       4.261541       4.366040\n",
       "2     4.006404  0.018691       3.969938       4.043205\n",
       "3     3.963245  0.026625       3.911403       4.015774\n",
       "4     3.555119  0.021661       3.512917       3.597829\n",
       "...        ...       ...            ...            ...\n",
       "5674  4.031204  0.014193       4.003482       4.059118\n",
       "5675  4.261949  0.038474       4.187205       4.338029\n",
       "5676  3.922421  0.021054       3.881373       3.963904\n",
       "5677  3.845409  0.017438       3.811384       3.879738\n",
       "5678  4.002508  0.015089       3.973042       4.032191\n",
       "\n",
       "[5679 rows x 4 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff82407f",
   "metadata": {},
   "source": [
    "This notebook explored the use of supervised learning techniques to model and predict a product rating variable. \n",
    "\n",
    "The linear regression model provided a strong and interpretable baseline, capturing the main relationships between the explanatory variables and the response. Building on this, a GLM was estimated to better reflect the distributional characteristics of the rating variable.\n",
    "\n",
    "Given that the response is strictly positive and right-skewed, a **Gamma GLM with a log link** was employed. This specification allows for a more appropriate probabilistic modeling of the data while retaining a linear structure in the predictors.\n",
    "\n",
    "From a predictive perspective, the GLM achieved a **Mean Absolute Error (MAE) of approximately 0.46** and a **Mean Squared Error (MSE) of approximately 0.50** on the test set. These results are comparable to those obtained with the linear regression model, indicating that both approaches capture similar predictive information from the available features.\n",
    "\n",
    "Although the GLM does not lead to a substantial improvement in point prediction accuracy, it provides additional benefits. In particular, the GLM framework allows for the construction of **prediction intervals** for the expected rating. The resulting confidence intervals are relatively narrow, suggesting **stable and well-calibrated predictions across the test set**.\n",
    "\n",
    "Overall, this analysis highlights that improvements in model specification do not necessarily translate into large gains in predictive accuracy when a simpler model already captures most of the signal. Nevertheless, the GLM offers a more statistically appropriate and interpretable framework for modeling the rating variable, reinforcing the robustness of the conclusions drawn from the linear regression analysis.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
